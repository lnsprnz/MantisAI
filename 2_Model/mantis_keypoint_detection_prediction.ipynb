{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from imgaug.augmentables.kps import KeypointsOnImage\n",
    "from imgaug.augmentables.kps import Keypoint\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters:\n",
    "IMG_SIZE: length and width of the Mantis Images\n",
    "\n",
    "BATCH_SIZE\n",
    "\n",
    "EPOCH\n",
    "\n",
    "NUM_KEYPOINTS: Number of Keypoints to detect. In this work we need to detect 5 Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 50\n",
    "NUM_KEYPOINTS = 5 * 2  # 5 pairs each having x and y coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get images and annotations of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR_TEST = r\"C:\\Users\\linus\\MantisAI\\MantisAI\\3_Model\\MantisAIData\\test\"\n",
    "JSON_TEST = r\"C:\\Users\\linus\\MantisAI\\MantisAI\\3_Model\\MantisAIData\\MantisTest.json\"\n",
    "KEYPOINT_DEF = r\"C:\\Users\\linus\\MantisAI\\MantisAI\\3_Model\\MantisKeypointDef.csv\"\n",
    "\n",
    "# Load the ground-truth annotations.\n",
    "with open(JSON_TEST) as infile:\n",
    "    json_data = json.load(infile)\n",
    "\n",
    "# Prepare the mapping for images and annotations\n",
    "images = {image['id']: image for image in json_data['images']}\n",
    "annotations = {annotation['image_id']: annotation for annotation in json_data['annotations']}\n",
    "\n",
    "# Process keypoints to ensure they are 2D\n",
    "raw_keypoints = annotations.get('keypoints', [])\n",
    "if raw_keypoints:\n",
    "  # Reshape the keypoints into a 2D array with shape (num_keypoints, 3)\n",
    "  reshaped_keypoints = [raw_keypoints[i:i + 3] for i in range(0, len(raw_keypoints), 3)]\n",
    "else:\n",
    "  reshaped_keypoints = []\n",
    "\n",
    "# Generate the desired output structure\n",
    "json_dict_test = {}\n",
    "for image_id, image_data in images.items():\n",
    "    annotation = annotations.get(image_id, {})\n",
    "\n",
    "    #convert joints to 2D Array\n",
    "    keypoints = annotation.get('keypoints', [])\n",
    "    joints_2d = np.array(keypoints).reshape(-1, 3) if keypoints else []\n",
    "\n",
    "    # Map the image and annotation data to the desired structure\n",
    "    json_dict_test[image_data['file_name']] = {\n",
    "        'img_bbox': annotation.get('bbox', []),\n",
    "        'img_height': image_data['height'],\n",
    "        'img_path': image_data['file_name'],\n",
    "        'img_width': image_data['width'],\n",
    "        'joints': joints_2d.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to get the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mantis_test(name):\n",
    "    \"\"\"\n",
    "    Loads the imae and its annotations for a given file name from the JSON data.\n",
    "\n",
    "    Args:\n",
    "             name(str) -- The name of the image to load, as listed in json_dict\n",
    "\n",
    "    Returns:\n",
    "                dict -- A dictionary with the following information:\n",
    "                    - img_bbox: The bounding box coordinates for the image\n",
    "                    - img_height: The height of the image in pixels\n",
    "                    - img_path: The path to the image file\n",
    "                    - img_width: The width of the image in pixels\n",
    "                    - joints: The joint coordinates/Keypoints for the image ([x,y,visibility])\n",
    "                    - img_data: The image data as a NumPy array\n",
    "    \"\"\"\n",
    "    data = json_dict_test[name]\n",
    "    img_data = plt.imread(os.path.join(IMG_DIR_TEST, data[\"img_path\"]))\n",
    "    # If the image is RGBA convert it to RGB.\n",
    "    if img_data.shape[-1] == 4:\n",
    "        img_data = img_data.astype(np.uint8)\n",
    "        img_data = Image.fromarray(img_data)\n",
    "        img_data = np.array(img_data.convert(\"RGB\"))\n",
    "    data[\"img_data\"] = img_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyPointsTestDataset(keras.utils.PyDataset):\n",
    "    def __init__(self, image_keys, aug, batch_size=BATCH_SIZE, train=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the KeyPointsDataset for managing and preprocessing test data.\n",
    "\n",
    "        Args:\n",
    "            image_keys (list): A list of image identifiers used to access the dataset\n",
    "            aug (callable): A function or object to apply data augmentation to images and keypoints\n",
    "            batch_size (int, optional): the number of samples per batch. Defaults to BATCH_SIZE\n",
    "            train (bool, optional): Indicates whether the dataset is used for Training (True) or Validation/Testing (False). Defaults to False\n",
    "\n",
    "        Returns:\n",
    "            Stores images keys, augmentation method, batch size, and mode (train/test)\n",
    "            Calls the on_epoch_end method to prepare the dataset for the first epoch\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.image_keys = image_keys\n",
    "        self.aug = aug\n",
    "        self.batch_size = batch_size\n",
    "        self.train = train\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculates the number of batches in the dataset.\"\"\"\n",
    "        return len(self.image_keys) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\" Prepares the dataset at the end of each epoch. (Generates a array of indices for the dataset and shuffles them if in training mode)\"\"\"\n",
    "        self.indexes = np.arange(len(self.image_keys))\n",
    "        # No shuffling for test data\n",
    "        #if self.train:\n",
    "        #    np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generates one batch of data.\n",
    "\n",
    "        Args: index(int): Batch index to retrieve\n",
    "        Returns: tuple (simplified definition: Ordered/sorted form of list): A tuple containing the batch of images and their corresponding keypoints\n",
    "        \"\"\"\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        image_keys_temp = [self.image_keys[k] for k in indexes]\n",
    "        (images, keypoints) = self.__data_generation(image_keys_temp)\n",
    "\n",
    "        return (images, keypoints)\n",
    "\n",
    "    def __data_generation(self, image_keys_temp):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses a batch of images and their keypoints.\n",
    "\n",
    "        Args:\n",
    "            image_keys_temp (list): A temporary list of image keys to load and preprocess\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - batch_images (np.ndarray): A batch of images\n",
    "                - batch_keypoints (np.ndarray): A batch of normalized keypoints\n",
    "        \"\"\"\n",
    "        batch_images = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3), dtype=\"int\")\n",
    "        batch_keypoints = np.empty(\n",
    "            (self.batch_size, 1, 1, NUM_KEYPOINTS), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        for i, key in enumerate(image_keys_temp):\n",
    "            data = get_mantis_test(key) # Assuming get_mantis function is defined elsewhere and handles test data\n",
    "            current_keypoint = np.array(data[\"joints\"])[:, :2]\n",
    "            kps = []\n",
    "\n",
    "            for j in range(0, len(current_keypoint)):\n",
    "                kps.append(Keypoint(x=current_keypoint[j][0], y=current_keypoint[j][1]))\n",
    "\n",
    "            current_image = data[\"img_data\"]\n",
    "            kps_obj = KeypointsOnImage(kps, shape=current_image.shape)\n",
    "\n",
    "            (new_image, new_kps_obj) = self.aug(image=current_image, keypoints=kps_obj)\n",
    "            batch_images[i,] = new_image\n",
    "\n",
    "            kp_temp = []\n",
    "            for keypoint in new_kps_obj:\n",
    "                kp_temp.append(np.nan_to_num(keypoint.x))\n",
    "                kp_temp.append(np.nan_to_num(keypoint.y))\n",
    "\n",
    "            batch_keypoints[i,] = np.array(kp_temp).reshape(1, 1, 5 * 2)\n",
    "\n",
    "        batch_keypoints = batch_keypoints / IMG_SIZE\n",
    "\n",
    "        return (batch_images, batch_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KeyPointsTestDataset(\n",
    "    list(json_dict_test.keys()), test_aug, workers=2, use_multiprocessing=True\n",
    ")\n",
    "\n",
    "model_test = keras.models.load_model(r\"C:\\Users\\linus\\MantisAI\\MantisAI\\3_Model\\MantisAI_TrainedModels\\mantisAIUnfreezeMobileNet.keras\")\n",
    "predictions = model_test.predict(test_dataset).reshape(-1, 5, 2) * IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a code that save the predicitions with the according image name as well as the ground truth values to a json file\n",
    "\n",
    "import json\n",
    "\n",
    "# Assuming 'predictions' is your array of predictions and 'test_dataset' is your test dataset\n",
    "# and 'test_keys' contains the file names in test dataset\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate through the predictions and filenames\n",
    "for i, pred in enumerate(predictions):\n",
    "    # Reshape the prediction as done previously (assuming a 5 keypoints setup)\n",
    "    reshaped_pred = pred.reshape(-1, 5, 2) * IMG_SIZE\n",
    "\n",
    "    # Get the corresponding image filename\n",
    "    image_filename = list(json_dict_test.keys())[i]\n",
    "\n",
    "    # Get the ground truth keypoints\n",
    "    data = get_mantis_test(image_filename)\n",
    "    ground_truth_keypoints = np.array(data[\"joints\"])[:, :2] # Extract only x,y coordinates\n",
    "\n",
    "    # Append to the result list\n",
    "    results.append({\n",
    "        \"image_name\": image_filename,\n",
    "        \"predictions\": reshaped_pred.tolist(),  # Convert numpy to list\n",
    "        \"ground_truth\": ground_truth_keypoints.tolist()  # Convert numpy to list\n",
    "    })\n",
    "\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('/content/drive/MyDrive/MantisModels/predictions.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
